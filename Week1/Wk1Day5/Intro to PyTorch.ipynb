{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions to answer\n",
    "\n",
    "Please write your answers on paper and include them in your folder.  We unfortunately likely won't have time to review them until this weekend, but we would like the opportunity to see how you are thinking about and discussing these questions with your group.\n",
    "\n",
    "## XOR network\n",
    "1. How does the XOR network here differ from the one we built yesterday?\n",
    "2. How does that difference impact the network's ability to classify?\n",
    "2. How does PyTorch handle creating network layers?\n",
    "3. How does PyTorch handle training networks?\n",
    "4. How does PyTorch handle testing networks?\n",
    "\n",
    "## $\\geq 5$ network\n",
    "1. How much better is performance using this network architecture?\n",
    "2. What modifications can you make to the network architecture or learning rate to result in better accuracy?\n",
    "3. How long does this network take to train before it stops improving or changing?\n",
    "\n",
    "## Digit classification network\n",
    "1. What accuracy does this network have?\n",
    "2. How many parameters does this network have?\n",
    "\n",
    "4. How long does this network take to train before it stops improving or changing?\n",
    "\n",
    "## Challenge problems\n",
    "1. A common activation function used now is the ReLU activation function.  Based on the PyTorch documentation at https://pytorch.org/docs/stable/index.html, how is it defined?  What impact does it have on your networks if you use it instead of tanh?\n",
    "3. In the PyTorch documentation there are other loss functions we can use.  What impact might switching the loss function have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\Program Files\\Python37\\Lib\\site-packages')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST data\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('MNIST/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('MNIST/', train=False, transform=transform, download=True)\n",
    "\n",
    "MNIST_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\n",
    "MNIST_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10000)\n",
    "\n",
    "\n",
    "\n",
    "# XOR data\n",
    "xor_inputs = torch.tensor(np.array([[1.0, 1], [0, 1], [1, 0], [0, 0]])).float()\n",
    "xor_labels = torch.tensor(np.array([0, 1, 1, 0])).float().view(-1, 1)\n",
    "\n",
    "xor_dataset = torch.utils.data.TensorDataset(xor_inputs, xor_labels)\n",
    "xor_loader = torch.utils.data.DataLoader(xor_dataset, batch_size=4)\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(-1, 2, 100)\n",
    "y = np.linspace(-1, 2, 100)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "x = xv.reshape(-1, 1)\n",
    "y = yv.reshape(-1, 1)\n",
    "\n",
    "xor_grid = torch.tensor(np.concatenate((x, y), axis=1)).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XORNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc2 = nn.Linear(3, 1)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "network = XORNet()\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01)\n",
    "\n",
    "lossFunc = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(xor_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = lossFunc(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in xor_loader:\n",
    "            output = network(data)\n",
    "            pred = output.data\n",
    "            correct += (pred > 0.5).long().eq(target.data.view_as(pred).long()).sum()\n",
    "    return 100. * correct / len(xor_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    if epoch % 50 == 0:\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        \n",
    "        \n",
    "        print('Epoch {}'.format(epoch))\n",
    "        acc = test()\n",
    "        \n",
    "        res = network(xor_grid).detach().numpy()\n",
    "        \n",
    "        ax1.scatter(x[res >= 0], y[res >= 0], c='r', label='+')\n",
    "        ax1.scatter(x[res < 0], y[res < 0], c='b', label='-')\n",
    "        ax1.set_title('f(x) >= 0')\n",
    "        ax1.set_xlim([-1, 2])\n",
    "        ax1.set_ylim([-1, 2])\n",
    "        ax1.set_xlabel('x')\n",
    "        ax1.set_ylabel('y')\n",
    "        ax1.legend()\n",
    "        \n",
    "        \n",
    "        ax2.plot_wireframe(xv, yv, res.reshape(xv.shape))\n",
    "        ax2.set_title('f(x)')\n",
    "        ax2.set_xlabel('x')\n",
    "        ax2.set_ylabel('y')\n",
    "        ax2.set_xlim([-1, 2])\n",
    "        ax2.set_ylim([-1, 2])\n",
    "        \n",
    "        fig.suptitle('epoch {}, accuracy {:.0f}%'.format(epoch, acc))\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\geq 5$ network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class greaterFiveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(greaterFiveNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "network = greaterFiveNet()\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01)\n",
    "\n",
    "lossFunc = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(MNIST_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        target = (target >= 5).float().view_as(output)\n",
    "        loss = lossFunc(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in MNIST_test_loader:\n",
    "            output = network(data)\n",
    "            pred = output.data\n",
    "            correct += (pred > 0.5).long().eq((target >= 5).data.view_as(pred).long()).sum()\n",
    "    print('Test set: Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "          correct, len(MNIST_test_loader.dataset),\n",
    "          100. * correct / len(MNIST_test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lossFunc = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(MNIST_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = lossFunc(output, F.one_hot(target, 10).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tAccuracy: {:.6f}'.format(\n",
    "                  epoch, batch_idx * len(data), len(MNIST_train_loader.dataset),\n",
    "                  100. * batch_idx / len(MNIST_train_loader), 100. * correct / 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in MNIST_test_loader:\n",
    "            output = network(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          correct, len(MNIST_test_loader.dataset),\n",
    "          100. * correct / len(MNIST_test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
